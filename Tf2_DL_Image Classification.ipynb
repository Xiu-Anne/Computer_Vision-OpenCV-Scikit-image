{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d5067-462f-410d-ab95-0cd3885721a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary tools\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub \n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"TF Hub version:\", hub.__version__)\n",
    "\n",
    "# Check for GPU availability\n",
    "print(\"GPU\", \"available (YESSSS!!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e1b61c-cfe0-413c-b5b9-d7bf253d5725",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f581ba-0b18-4caa-8d0b-e353082b0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout the labels of our data\n",
    "labels_csv = pd.read_csv(\"data/Dog Vision/labels.csv\")\n",
    "print(labels_csv.describe())\n",
    "print(labels_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fc044-dd8e-494e-b2ac-ceb0757df263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images are there of each breed?\n",
    "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf42c8a-4452-47f1-b415-bdd1921e0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pathnames from image ID's\n",
    "filenames = [\"data/Dog Vision/train/\" + fname + \".jpg\" for fname in labels_csv[\"id\"]]\n",
    "\n",
    "# Check the first 10\n",
    "filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f221d-7298-4f72-a5a1-7e71a847c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_csv[\"breed\"].to_numpy() # labels = np.array(labels) # does same thing as above\n",
    "# Find the unique label values\n",
    "unique_breeds = np.unique(labels)\n",
    "len(unique_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d808c5-8cb4-4228-b862-b090e5a91b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if number of labels matches the number of filenames\n",
    "if len(labels) == len(filenames):\n",
    "  print(\"Number of labels matches number of filenames!\")\n",
    "else:\n",
    "  print(\"Number of labels does not match number of filenames, check data directories!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9d1c5-3d1e-4ac0-bbf1-70b03009da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn every label into a boolean array\n",
    "boolean_labels = [label == unique_breeds for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9481d2-540f-4165-8113-76e5d43bdc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup X & y variables\n",
    "X = filenames\n",
    "y = boolean_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d11bea-406a-4020-9d70-223d12b0cdd1",
   "metadata": {},
   "source": [
    "### Split into train & validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50bd1a1-69c3-4807-a1a8-cd9256b7758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split our data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "NUM_IMAGES = 1000\n",
    "\n",
    "# Split them into training and validation of total size NUM_IMAGES\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
    "                                                  y[:NUM_IMAGES],\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eff553-3cc6-495c-8934-c652b98a28ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Create a function for preprocessing images\n",
    "def process_image(image_path, img_size=IMG_SIZE):\n",
    "  \"\"\"\n",
    "  Takes an image file path and turns the image into a Tensor.\n",
    "  \"\"\"\n",
    "  # Read in an image file\n",
    "  image = tf.io.read_file(image_path)\n",
    "  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  # Convert the colour channel values from 0-255 to 0-1 values\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  # Resize the image to our desired value (224, 224)\n",
    "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
    "\n",
    "  return image\n",
    "\n",
    "# Create a simple function to return a tuple (image, label)\n",
    "def get_image_label(image_path, label):\n",
    "  \"\"\"\n",
    "  Takes an image file path name and the assosciated label,\n",
    "  processes the image and reutrns a typle of (image, label).\n",
    "  \"\"\"\n",
    "  image = process_image(image_path)\n",
    "  return image, label\n",
    "\n",
    "# Define the batch size, 32 is a good start\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create a function to turn data into batches\n",
    "def create_data_batches(X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
    "  \"\"\"\n",
    "  Creates batches of data out of image (X) and label (y) pairs.\n",
    "  Shuffles the data if it's training data but doesn't shuffle if it's validation data.\n",
    "  Also accepts test data as input (no labels).\n",
    "  \"\"\"\n",
    "  # If the data is a test dataset, we probably don't have have labels\n",
    "  if test_data:\n",
    "    print(\"Creating test data batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths (no labels)\n",
    "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "  \n",
    "  # If the data is a valid dataset, we don't need to shuffle it\n",
    "  elif valid_data:\n",
    "    print(\"Creating validation data batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n",
    "                                               tf.constant(y))) # labels\n",
    "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "\n",
    "  else:\n",
    "    print(\"Creating training data batches...\")\n",
    "    # Turn filepaths and labels into Tensors\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n",
    "                                               tf.constant(y)))\n",
    "    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n",
    "    data = data.shuffle(buffer_size=len(X))\n",
    "\n",
    "    # Create (image, label) tuples (this also turns the iamge path into a preprocessed image)\n",
    "    data = data.map(get_image_label)\n",
    "\n",
    "    # Turn the training data into batches\n",
    "    data_batch = data.batch(BATCH_SIZE)\n",
    "  return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9b467-443c-4b17-bcde-73898e73552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation data batches\n",
    "train_data = create_data_batches(X_train, y_train)\n",
    "val_data = create_data_batches(X_val, y_val, valid_data=True)\n",
    "\n",
    "# Check out the different attributes of our data batches\n",
    "train_data.element_spec, val_data.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b7419-a459-4430-8830-a2fffa88c85a",
   "metadata": {},
   "source": [
    "### Visualization data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ee6df-065d-4387-afd5-92239ca5e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a function for viewing images in a data batch\n",
    "def show_25_images(images, labels):\n",
    "  \"\"\"\n",
    "  Displays a plot of 25 images and their labels from a data batch.\n",
    "  \"\"\"\n",
    "  # Setup the figure\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  # Loop through 25 (for displaying 25 images)\n",
    "  for i in range(25):\n",
    "    # Create subplots (5 rows, 5 columns)\n",
    "    ax = plt.subplot(5, 5, i+1)\n",
    "    # Display an image \n",
    "    plt.imshow(images[i])\n",
    "    # Add the image label as the title\n",
    "    plt.title(unique_breeds[labels[i].argmax()])\n",
    "    # Turn the grid lines off\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff4a65-08df-4c6f-83b3-22b821466052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's visualize the data in a training batch\n",
    "train_images, train_labels = train_images, train_labels = next(train_data.as_numpy_iterator())\n",
    "show_25_images(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4175161-3492-4df3-b1ff-f8c94a1f707e",
   "metadata": {},
   "source": [
    "## Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed66d8c9-a928-44e0-b176-91e57adfc8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use the whole model: MODEL_URL\n",
    "# Setup input shape to the model\n",
    "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n",
    "\n",
    "# Setup output shape of our model\n",
    "OUTPUT_SHAPE = len(unique_breeds)\n",
    "\n",
    "# Setup model URL from TensorFlow Hub\n",
    "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\"\n",
    "\n",
    "# Create a function which builds a Keras model\n",
    "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
    "  print(\"Building model with:\", MODEL_URL)\n",
    "\n",
    "  # Setup the model layers\n",
    "  model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
    "    tf.keras.layers.Dense(units=OUTPUT_SHAPE,\n",
    "                          activation=\"softmax\") # Layer 2 (output layer)\n",
    "  ])\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      optimizer=tf.keras.optimizers.Adam(),\n",
    "      metrics=[\"accuracy\"]\n",
    "  )\n",
    "\n",
    "  # Build the model\n",
    "  model.build(INPUT_SHAPE)\n",
    "\n",
    "  return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551d08e-83e1-4253-aeb4-98672406543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "# Setup output shape of our model\n",
    "OUTPUT_SHAPE = len(unique_breeds)\n",
    "\n",
    "# Create a function which builds a Keras model\n",
    "def create_model(input_shape=IMG_SHAPE, output_shape=OUTPUT_SHAPE):\n",
    "    print(\"Building model based on MobileNetV2\")\n",
    "\n",
    "    # Pre-trained model with MobileNetV2\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=IMG_SHAPE,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    # Freeze the pre-trained model weights\n",
    "    base_model.trainable = False\n",
    "    # Trainable classification head\n",
    "    maxpool_layer = tf.keras.layers.GlobalMaxPooling2D()\n",
    "    prediction_layer = tf.keras.layers.Dense(OUTPUT_SHAPE, activation='softmax')\n",
    "    \n",
    "    # Layer classification head with feature detector\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        maxpool_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "      optimizer=tf.keras.optimizers.Adam(),\n",
    "      metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77180b9c-73dc-43c8-9525-fe331cf9bb5c",
   "metadata": {},
   "source": [
    "## Creating callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0939a-d619-41eb-b7eb-f2ae49218b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82fea0-912f-4f22-877c-51a4288f967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Create a function to build a TensorBoard callback\n",
    "def create_tensorboard_callback():\n",
    "  # Create a log directory for storing TensorBoard logs\n",
    "  logdir = os.path.join(\"data/Dog Vision/logs\",\n",
    "                        # Make it so the logs get tracked whenever we run an experiment\n",
    "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  return tf.keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0d48c-9a2e-4da6-843d-5ae35a53c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
    "                                                  patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c03212-5240-48b3-8827-75de6a3e438a",
   "metadata": {},
   "source": [
    "## Training a model (on subset of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1173e017-6d7f-427a-b112-c51b3e873264",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86be9e-3171-4623-92c9-b832ba28cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function to train and return a trained model\n",
    "def train_model():\n",
    "  \"\"\"\n",
    "  Trains a given model and returns the trained version.\n",
    "  \"\"\"\n",
    "  # Create a model\n",
    "  model = create_model()\n",
    "\n",
    "  # Create new TensorBoard session everytime we train a model\n",
    "  tensorboard = create_tensorboard_callback()\n",
    "\n",
    "  # Fit the model to the data passing it the callbacks we created\n",
    "  model.fit(x=train_data,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            validation_data=val_data,\n",
    "            validation_freq=1,\n",
    "            callbacks=[tensorboard, early_stopping])\n",
    "  # Return the fitted model\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8b031d-1bf1-4441-8876-224e10d4a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data\n",
    "model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd3e97-e417-4775-8c07-1fc3dc79c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the TensorBoard logs\n",
    "#%tensorboard --logdir data/Dog Vision/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb54f3-9718-44a1-ad4c-115237460c78",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd186d77-082e-48ae-acb7-b36a377a2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the pre-saved model\n",
    "model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829d903-d9b1-462f-849d-f29563b7d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation data (not used to train on)\n",
    "predictions = model.predict(val_data, verbose=1)\n",
    "\n",
    "# Turn prediction probabilities into their respective label (easier to understand)\n",
    "def get_pred_label(prediction_probabilities):\n",
    "  \"\"\"\n",
    "  Turns an array of prediction probabilities into a label.\n",
    "  \"\"\"\n",
    "  return unique_breeds[np.argmax(prediction_probabilities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8e728-8f84-4871-8ed2-77536ed4f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a predicted label based on an array of prediction probabilities\n",
    "pred_label = get_pred_label(predictions[81])\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c305cc-e9da-46e2-80e7-62d1c290aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to unbatch a batch dataset\n",
    "def unbatchify(data):\n",
    "  \"\"\"\n",
    "  Takes a batched dataset of (image, label) Tensors and reutrns separate arrays\n",
    "  of images and labels.\n",
    "  \"\"\"\n",
    "  images = []\n",
    "  labels = []\n",
    "  # Loop through unbatched data\n",
    "  for image, label in data.unbatch().as_numpy_iterator():\n",
    "    images.append(image)\n",
    "    labels.append(unique_breeds[np.argmax(label)])\n",
    "  return images, labels\n",
    "\n",
    "# Unbatchify the validation data\n",
    "val_images, val_labels = unbatchify(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf608d7-ae07-4344-9ab1-943c4cbe0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(prediction_probabilities, labels, images, n=1):\n",
    "  \"\"\"\n",
    "  View the prediction, ground truth and image for sample n\n",
    "  \"\"\"\n",
    "  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n",
    "\n",
    "  # Get the pred label\n",
    "  pred_label = get_pred_label(pred_prob)\n",
    "\n",
    "  # Plot image & remove ticks\n",
    "  plt.imshow(image)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  # Change the colour of the title depending on if the prediction is right or wrong\n",
    "  if pred_label == true_label:\n",
    "    color = \"green\"\n",
    "  else:\n",
    "    color = \"red\"\n",
    "  \n",
    "  # Change plot title to be predicted, probability of prediction and truth label\n",
    "  plt.title(\"{} {:2.0f}% {}\".format(pred_label,\n",
    "                                    np.max(pred_prob)*100,\n",
    "                                    true_label),\n",
    "                                    color=color)\n",
    "\n",
    "plot_pred(prediction_probabilities=predictions,\n",
    "          labels=val_labels,\n",
    "          images=val_images,\n",
    "          n=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5574b0-754e-43db-8cea-dcb820744c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_conf(prediction_probabilities, labels, n=1):\n",
    "  \"\"\"\n",
    "  Plus the top 10 highest prediction confidences along with the truth label for sample n.\n",
    "  \"\"\"\n",
    "  pred_prob, true_label = prediction_probabilities[n], labels[n]\n",
    "\n",
    "  # Get the predicted label\n",
    "  pred_label = get_pred_label(pred_prob)\n",
    "\n",
    "  # Find the top 10 prediction confidence indexes\n",
    "  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n",
    "  # Find the top 10 prediction confidence values\n",
    "  top_10_pred_values = pred_prob[top_10_pred_indexes]\n",
    "  # Find the top 10 prediction labels\n",
    "  top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n",
    "\n",
    "  # Setup plot\n",
    "  top_plot = plt.bar(np.arange(len(top_10_pred_labels)),\n",
    "                     top_10_pred_values,\n",
    "                     color=\"grey\")\n",
    "  plt.xticks(np.arange(len(top_10_pred_labels)),\n",
    "             labels=top_10_pred_labels,\n",
    "             rotation=\"vertical\")\n",
    "  \n",
    "  # Change color of true label\n",
    "  if np.isin(true_label, top_10_pred_labels):\n",
    "    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n",
    "  else:\n",
    "    pass\n",
    "\n",
    "plot_pred_conf(prediction_probabilities=predictions,\n",
    "               labels=val_labels,\n",
    "               n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10de22e-ef5a-463b-a10d-e75ad28e2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out a few predictions and their different values\n",
    "i_multiplier = 20\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(10*num_cols, 5*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_pred(prediction_probabilities=predictions,\n",
    "            labels=val_labels,\n",
    "            images=val_images,\n",
    "            n=i+i_multiplier)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_pred_conf(prediction_probabilities=predictions,\n",
    "                 labels=val_labels,\n",
    "                 n=i+i_multiplier)\n",
    "plt.tight_layout(h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc7b6f-18cc-43b1-b4d5-fcb4d0c0c0b7",
   "metadata": {},
   "source": [
    "## Saving and reloading a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee233ce9-5bfa-412e-a44c-4de937cd8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to save a model\n",
    "def save_model(model, suffix=None):\n",
    "  \"\"\"\n",
    "  Saves a given model in a models directory and appends a suffix (string).\n",
    "  \"\"\"\n",
    "  # Create a model directory pathname with current time\n",
    "  modeldir = os.path.join(\"data/Dog Vision/models\",\n",
    "                          )#datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\")\n",
    "  model_path = modeldir + \"-\" + suffix + \".h5py\" # save format of model\n",
    "  print(f\"Saving model to: {model_path}...\")\n",
    "  model.save(model_path)\n",
    "  return model_path\n",
    "\n",
    "# Create a function to load a trained model\n",
    "def load_model(model_path):\n",
    "  \"\"\"\n",
    "  Loads a saved model from a specified path.\n",
    "  \"\"\"\n",
    "  print(f\"Loading saved model from: {model_path}\")\n",
    "  model = tf.keras.models.load_model(model_path, \n",
    "                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c544b-6213-43be-8ea6-4cb1607b3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our model trained on 1000 images\n",
    "save_model(model, suffix=\"1000-images-mobilenetv2-Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710a890-4819-4efd-b427-2dfa148309e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model\n",
    "loaded_1000_image_model = load_model('data/Dog Vision/models-1000-images-mobilenetv2-Adam.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770ac9b-3909-48e9-a493-a991032bc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the loaded model\n",
    "loaded_1000_image_model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a0bc7-cc59-46bb-b896-a43d6f6c0323",
   "metadata": {},
   "source": [
    "## Making predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1396ea-42a5-4c31-87f8-92e9a0ecdafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image filenames\n",
    "test_path = \"data/Dog Vision/test/\"\n",
    "test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n",
    "test_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ede330-02b0-4a21-855b-5893727f0123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data batch\n",
    "test_data = create_data_batches(test_filenames, test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec363ac7-4102-4646-9022-b29b939d9e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data batch using the loaded full model\n",
    "test_predictions = loaded_1000_image_model.predict(test_data,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621b7c1-f235-44d6-a44f-33540e6de9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions (NumPy array) to csv file (for access later)\n",
    "np.savetxt(\"data/Dog Vision/preds_array.csv\", test_predictions, delimiter=\",\")\n",
    "\n",
    "# Load predictions (NumPy array) from csv file\n",
    "#test_predictions = np.loadtxt(\"data/Dog Vision/preds_array.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72a6e0-f7c7-4e12-bd8d-eb633a47b395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb590e0-762b-4266-9008-be6e4aa81ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
